# SSAFY 7기 특화프로젝트

> 도메인: 빅데이터(분산처리)



* 팀장: 정종일
* 팀원: 김민정, 박지은, 오도석, 최연지
* 프로젝트 기간: 2022.08.22 ~ 2022.10.07 (7주)
* 프로젝트명: 酒酒클럽
* 프로젝트 소개: 태그 기반 전통주 추천 및 푸드 페어링 정보 공유 서비스

<br>

## 목차

* [프로젝트 기술 스택](#프로젝트-기술-스택)
* [Jira Burndown Chart](#jira-burndown-chart)
* [Timeline](#timeline)
  * [2주차](#2주차)
  * [3주차](#3주차)
  * [4주차](#4주차)
  * [5주차](#5주차)
  * [6주차](#6주차)
* [느낀점](#느낀점)

<br>

## 프로젝트 기술 스택

1. 이슈관리: Jira

2. 형상관리: Gitlab

3. 커뮤니케이션: Mattermost, Notion, Webex

4. 개발 환경

   a) OS: Windows 10 

   b) IDE

   ​	i) IntelliJ IDEA 2022.1.4

   ​	ii) Visual Studio Code 1.69.0

   c) Database: MySQL Ver 8.0.30

   d) Server: AWS EC2(MobaXterm 22.1)

   ​	i) Ubuntu 20.04.2 LTS

   ​	ii) Jenkins 2.346.2

   e) Storage: AWS S3

5. 상세내용

   a) BackEnd 

   ​	i) Java 1.8.0 

   ​	ii) Spring Boot Gradle 7.5 

   ​	iii) Lombok 1.18.24, Swagger2  

   ​	iv) jjwt 0.9.1 

   b) FrontEnd 

   ​	i) Vue: 2.6.14 

   ​	ii) Vuex: 3.6.2 

   ​	iii) vue-router: 3.5.1 

   c) Big Data Dispersion 4 

   ​	i) Python 3.10.5 

   ​	ii) hadoop-3.2.3 

   ​	iii) sqoop-1.4.7 

   ​	iv) spark-3.2.2

<br>

## Jira Burndown Chart

1. 2주차 (프로젝트 기획, 데이터 크롤링)

   ![image-20221006133911152](README.assets/image-20221006133911152.png)

2. 3주차 (ERD, Figma, 빅데이터 분산처리 시작, 프론트 및 백엔드 개발 시작)

   ![image-20221006133926429](README.assets/image-20221006133926429.png)

3. 4주차 (데이터 분산처리 완료, 프론트 및 백엔드 개발 진행)

   ![image-20221006133941935](README.assets/image-20221006133941935.png)

4. 5주차 (프론트 및 백엔드 에러 처리)

   ![image-20221006133955975](README.assets/image-20221006133955975.png)

5. 6주차 (프론트 및 백엔드 에러 처리, 발표 준비, Documentation)

   ![image-20221006134121457](README.assets/image-20221006134121457.png)

<br>

## Timeline

```
💡	프로젝트 진행 기간 중 이슈, 사건을 기준으로 시간 순 회고
```

### 2주차

> 프로젝트 기획, 데이터 크롤링

* 파이썬으로 전통주 정보와 네이버 후기를 크롤링하는 코드 작성 후 크롤링 시작
* 네이버 후기 크롤링 도중 팀원마다 다른 시점에서 크롤링이 중단되는 이슈 발생
  - 원인: pagination 버튼이 가려지는 경우 크롤링이 중단
  - 해결: 스크롤이 내려가는 범위를 제한해서 항상 pagination 버튼이 보이도록 수정
* 네이버에서 여러 판매처를 모아둔 쇼핑몰 사이트의 경우 후기를 2천개까지만 볼 수 있음
* 네이버 일반 쇼핑몰에서는 후기를 2만개까지만 크롤링할 수 있음



### 3주차

> ERD, Figma, 빅데이터 분산처리 시작, 프론트 및 백엔드 개발 시작

* 2주차 주말 및 연휴동안 데이터 크롤링 완료

* Figma 및 ERD 작성
* Hadoop, Spark 사전학습 및 설치
* python에서 지원되는 맞춤법 검사 라이브러리인 py-hanspell 설치가 안됨
  - python 버전 문제라고 생각해 python을 여러 버전으로 설치해봤으나 실패
  - vmware에서 python을 지우면 터미널이 까맣게 된 상태로 컴퓨터가 멈춘다.
  - 새로운 계정을 만들고 명령어를 바꿔서 설치하니까 성공 (파이썬 버전 문제가 아님)
* 프론트 및 백엔드 개발 시작



### 4주차

> 데이터 분산처리 완료, 프론트 및 백엔드 개발 진행

* 빅데이터 분산처리 완료
  - 형태소 분석 시 PicklingError
    - 원인: 파이썬 코드 내에서 잘못된 참조
    - 해결: 파이썬 내장변수 `__name__` 사용
* 프론트, 백엔드 개발 진행
  - 프론트엔드
    - API 호출 후 데이터 출력 과정에서 `unknown type error`
      - 원인: 비동기 API 호출 시 데이터를 받아오는 시간이 페이지 렌더링 시간보다 오래 걸림
      - 해결: 컴포넌트 내에 data를 null 값으로 사전 설정 or `setTimeout` 함수를 이용



### 5주차

> 프론트 및 백엔드 에러 처리

* Feed 생성 및 수정 시 S3 이용 관련하여 403 에러
  - 백과 프론트 수정
* 기타 에러 처리



### 6주차

> 프론트 및 백엔드 에러 처리, 발표 준비, Documentation

* 프론트: 기능 마무리 및 CSS 수정
* 백엔드: “좋아요”를 누른 Feed 삭제 버튼을 누를 경우 pk 참조 이슈로 Feed가 삭제되지 않는 문제 발생, 해결
* 발표 PPT, UCC 제작
* 포팅 매뉴얼, 회고 작성 등 Documentation

<br>

## 느낀점

```
📌 프로젝트를 마무리하면서..
```

### 김민정

```
 이번 프로젝트에서 처음으로 Hadoop과 Spark를 사용해 봤는데, 프로젝트 초반에는 어떻게 데이터가 처리되는지 감을 잡을 수 없어 많이 헤맸던 것 같다. 데이터를 어떤 식으로 처리할지 팀원들과 계속해서 회의하고 그에 맞춰서 pyspark 공식 문서를 매일 찾아보며 데이터를 한 단계씩 처리해 나갈 수 있었다. 파이썬으로 크롤링 코드를 짜는 것부터 빅데이터 분산처리를 하는 것까지 일련의 과정들을 거치면서 이렇게 빅데이터를 처리해 볼 수 있다는 것이 즐거웠다.
 빅데이터 처리와 프론트 업무를 번갈아가면서 하다 보니 조금 정신없었지만 팀원들 모두 밤늦게까지 소통하며 프로젝트에 임했기 때문에 더 힘을 내서 개발할 수 있었고, 그렇기 때문에 이렇게 성공적으로 프로젝트를 마무리할 수 있었던 것 같다.
 프로젝트를 진행하면서 겪었던 다양한 에러들을 개인 블로그에 저장하는 습관이 생겼는데, 다음 프로젝트 때 비슷한 에러가 나온다면 이번보다 더 빨리 해결할 수 있을 것이라고 기대한다.
```

### 박지은

```
 프로젝트 초반에는 생각보다 순탄했던 기획과정과 이전에 경험이 있던 크롤링을 진행하면서 처음 협업하는 팀원들과 호흡을 맞춰갔고, 이후 개발 과정에서 발생한 문제들을 함께 해결하는데 도움이 된 것 같았다. 또한 처음으로 비정형데이터를 다루는 프로젝트를 진행한 것도 처음이었는데 비정형 데이터의 분석과정과 자연어 전처리 과정을 스스로 찾아보면서 새로운 것을 학습할 수 있는 기회가 되었다. 또한 처음으로 프론트 역할을 맡아 vue 를 사용하면서 이전 프로젝트들 보다 걱정과 두려움이 많이 앞선채로 시작한 프로젝트였다. 결과적으로 프론트 개발 경험과 비정형 데이터 분석 과정에 대한 이해도를 높일 수 있었던 좋은 기회였다고 생각한다.
```

### 오도석

```
프로젝트를 진행하기 전에 목표는 Hadoop을 비롯한 새로운 tool을 사용해보는 것과 단순 배포 자동화가 아니라 무중단 배포 등과 같은 이전 프로젝트에서 조금 더 업그레이드된 프로젝트를 원했고 mybatis대신 jpa를 사용하고 junit을 사용한 단위테스트까지 하는 등의 많은 성과를 이뤄냈다고 생각한다.
백엔드를 담당하면서 새로운 기술을 사용하는 것도 중요했지만 보안 측면에서 매우 부족했는데 다음 프로젝트 때는 트래픽처리와 보안관리 등에 조금 더 신경을 써서 프로젝트를 진행해보고 싶다.
```

### 정종일

```
 프론트엔드 개발을 맡은 건 처음이라 상당한 부담감이 있었지만 각자 열심히 공부하고 같은 프론트엔드 팀원과 정보도 공유하며 생각보다 아주 괜찮은 산출물을 만들어냈다. 다만 중간에 Vue Life Cycle에 대한 이해가 미숙해 비동기 처리시 API 요청과 별개로 컴포넌트가 렌더링되어 데이터가 출력되지 않는 이슈가 있었지만 Vue 공식문서를 참고해 잘 해결해 다행이었다.
 이번 프론트엔드 역할을 맡으며 백엔드 쪽에서 데이터를 넘겨줄 때 프론트엔드가 원하는 형태로 가공해 넘겨주면 코드도 깔끔해지고 상호 간의 의사소통도 더욱 쉬워진다는 것을 많이 체감했고 이를 토대로 추후 백엔드 역할을 맡을 때 적용시킬 수 있으리라 생각한다.
 팀장 역할을 수행하면서 정말 부족한 부분도 많았고 챙기지 못한 부분도 많았지만 팀원들이 해당 부분을 잘 캐치해 리마인드 시켜주고 팀장역할을 편하게 수행할 수 있도록 잘 서포트해주었다. 팀원 간 의사소통의 중요성, 리더로서 어떠한 팔로워일 때 역할 수행이 원활하게 되는지도 느낄 수 있는 프로젝트였다.
 이번 프로젝트를에서 본인이 가고자 하는 방향과는 다른 역할들을 수행했는데 이 과정에서 본인이 생각하지 못한 이슈들, 의사소통의 문제점들을 파악할 수 있었고 협업하는 사람의 입장을 느껴볼 수 있는 소중한 시간이었다.
```

### 최연지

```
특화 프로젝트를 진행하며 예상과는 다르게 Hadoop과 Spark를 추가로 다루게 되어 진행하는 동안 부담감이 컸었다. 대부분의 개념과 기술들이 처음 접하는 것이라 낯설기도 했지만 팀원과 분산 처리 과정에 대해 소통하며 단계별로 진행하였고, 도움을 받아가며 성공적으로 데이터 처리를 할 수 있었다. 
이후 백엔드를 개발하며 프론트와의 원활한 데이터 전달을 위해 API 명세 작성을 상세히 하려고 노력하였다. 이전 공통 프로젝트에서는 Swagger 외에는 API 명세를 자세히 작성하지 않아 프론트와의 요청/응답 데이터에 대해 소통을 하면서 의도치 않게 많은 시간을 허비했다고 느꼈기에 이를 개선하고자 하였다. 명세서를 통해 특정 API를 언제든 확인할 수 있었고, 프론트에서 원하는 응답 데이터 형태가 있을 경우 서로 명세서를 공유하며 편하게 수정이 가능했다. 또한 개발의 진행상황을 쉽게 공유하고 팀원 간의 의사소통이 한결 수월해짐을 경험할 수 있었다.
```

